{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792c04e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d3ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/john/ds5030/understanding_uncertainty/data/ames_prices.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e40395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: create a DataFrame with a categorical column and show categories\n",
    "df = pd.DataFrame({'category': ['A', 'B', 'C', 'D', 'E', 'F']})\n",
    "# convert to categorical dtype (required to use .cat)\n",
    "df['category'] = df['category'].astype('category')\n",
    "print('Example categories for df:', df['category'].cat.categories)\n",
    "\n",
    "# Example 2: show categories for a real dataset column if present\n",
    "if 'data' in globals():\n",
    "    col = 'MS Zoning'  # change to any categorical column name in your dataset\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].astype('category')\n",
    "        print('\\nCategories for', col, ':', data[col].cat.categories)\n",
    "    else:\n",
    "        print('\\nColumn', col, 'not found in data; available columns:', list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'data' in globals():\n",
    "    col1 = 'Fireplaces'  # change to any categorical column name in your dataset\n",
    "    col2 = 'Pool.Area'  # change to another categorical column name in your dataset\n",
    "    if col1 in data.columns and col2 in data.columns:\n",
    "        contingency_table = pd.crosstab(data[col1], data[col2])\n",
    "        print('\\nContingency table between', col1, 'and', col2, ':\\n', contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68015f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Fireplaces', 'Pool.Area']].isnull().sum()\n",
    "#summarize the contingency table in percentages.\n",
    "if 'data' in globals():\n",
    "    col1 = 'Fireplaces'  # change to any categorical column name in your dataset\n",
    "    col2 = 'Pool.Area'  # change to another categorical column name in your dataset\n",
    "    if col1 in data.columns and col2 in data.columns:\n",
    "        contingency_table = pd.crosstab(data[col1], data[col2], normalize='index') * 100\n",
    "        print('\\nContingency table (in percentages) between', col1, 'and', col2, ':\\n', contingency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2fa074",
   "metadata": {},
   "source": [
    "## Interesting Patterns\n",
    "\n",
    "I chose the Ames housing data because it has clean data for both of the variables I chose: fireplaces and pools as expressed in pool area. I summarized the data as percentages and found it interesting that 100% of the houses with four fireplaces, the largest number, also have the largest number sized pool are of 800 square feet. I have to believe this is the head coach's house of the Iowa State football team resident in Ames. Also, most people in Ames don't have pools until they have three fireplaces. Makes sense that larger, more well appointed houses would be the ones to have pools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c27af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('nhanes_data_17_18.csv')\n",
    "\n",
    "# Define our variables\n",
    "Y = 'FeelingBadAboutYourself'  # Numeric dependent variable\n",
    "X = 'EverUsedHeroin'           # Categorical independent variable\n",
    "\n",
    "# Clean the data - remove missing values for both variables\n",
    "clean_df = df[[X, Y]].dropna()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NHANES ANALYSIS: FeelingBadAboutYourself by EverUsedHeroin\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOriginal dataset size: {len(df):,} observations\")\n",
    "print(f\"Complete cases for analysis: {len(clean_df):,} observations\")\n",
    "print(f\"Missing data removed: {len(df) - len(clean_df):,} observations\")\n",
    "\n",
    "# Convert EverUsedHeroin to categorical labels for better interpretation\n",
    "# Assuming typical NHANES coding: 1=Yes, 2=No\n",
    "clean_df['Heroin_Use'] = clean_df[X].map({1: 'Yes', 2: 'No'})\n",
    "clean_df['Heroin_Use'] = clean_df['Heroin_Use'].fillna('Unknown')\n",
    "\n",
    "print(f\"\\nHeroin Use Categories:\")\n",
    "print(clean_df['Heroin_Use'].value_counts())\n",
    "\n",
    "# 1. DESCRIPTIVE STATISTICS TABLE\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"1. DESCRIPTIVE STATISTICS TABLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Overall statistics\n",
    "overall_stats = clean_df[Y].describe()\n",
    "print(f\"\\nOverall Statistics for {Y}:\")\n",
    "print(overall_stats.round(3))\n",
    "\n",
    "# Grouped statistics\n",
    "grouped_stats = clean_df.groupby('Heroin_Use')[Y].describe()\n",
    "print(f\"\\nGrouped Statistics for {Y} by Heroin Use:\")\n",
    "print(grouped_stats.round(3))\n",
    "\n",
    "# Additional statistics\n",
    "def additional_stats(series):\n",
    "    return pd.Series({\n",
    "        'skewness': stats.skew(series),\n",
    "        'kurtosis': stats.kurtosis(series),\n",
    "        'variance': np.var(series, ddof=1),\n",
    "        'iqr': np.percentile(series, 75) - np.percentile(series, 25),\n",
    "        'median_abs_dev': np.median(np.abs(series - np.median(series)))\n",
    "    })\n",
    "\n",
    "print(f\"\\nAdditional Statistics by Heroin Use:\")\n",
    "additional = clean_df.groupby('Heroin_Use')[Y].apply(additional_stats)\n",
    "print(additional.round(3))\n",
    "\n",
    "# 2. FREQUENCY TABLES\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. FREQUENCY TABLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cross-tabulation\n",
    "crosstab = pd.crosstab(clean_df[Y], clean_df['Heroin_Use'], margins=True)\n",
    "print(f\"\\nCross-tabulation: {Y} by Heroin Use\")\n",
    "print(crosstab)\n",
    "\n",
    "# Proportions within each heroin use category\n",
    "prop_table = pd.crosstab(clean_df[Y], clean_df['Heroin_Use'], normalize='columns')\n",
    "print(f\"\\nColumn Proportions (within Heroin Use category):\")\n",
    "print(prop_table.round(3))\n",
    "\n",
    "# 3. STATISTICAL TESTS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3. STATISTICAL TESTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# T-test (if we have Yes/No groups)\n",
    "groups = clean_df.groupby('Heroin_Use')[Y].apply(list)\n",
    "if len(groups) == 2:\n",
    "    group1, group2 = groups.iloc[0], groups.iloc[1]\n",
    "    t_stat, p_value = stats.ttest_ind(group1, group2)\n",
    "    print(f\"\\nIndependent t-test:\")\n",
    "    print(f\"t-statistic: {t_stat:.4f}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "    \n",
    "# Mann-Whitney U test (non-parametric alternative)\n",
    "if len(groups) == 2:\n",
    "    u_stat, u_p_value = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "    print(f\"\\nMann-Whitney U test (non-parametric):\")\n",
    "    print(f\"U-statistic: {u_stat:.4f}\")\n",
    "    print(f\"p-value: {u_p_value:.4f}\")\n",
    "\n",
    "# ANOVA (if more than 2 groups)\n",
    "if len(groups) > 2:\n",
    "    f_stat, f_p_value = stats.f_oneway(*groups)\n",
    "    print(f\"\\nOne-way ANOVA:\")\n",
    "    print(f\"F-statistic: {f_stat:.4f}\")\n",
    "    print(f\"p-value: {f_p_value:.4f}\")\n",
    "\n",
    "# 4. VISUALIZATIONS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4. CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Set up the plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create figure with subplots\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# 1. Kernel Density Plots\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "for group_name, group_data in clean_df.groupby('Heroin_Use'):\n",
    "    if len(group_data) > 1:  # Only plot if we have enough data\n",
    "        sns.kdeplot(data=group_data[Y], label=f'{group_name} (n={len(group_data)})', \n",
    "                   fill=True, alpha=0.6)\n",
    "plt.xlabel('Feeling Bad About Yourself Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Kernel Density Plot by Heroin Use')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Box Plot\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "sns.boxplot(data=clean_df, x='Heroin_Use', y=Y)\n",
    "plt.title('Box Plot by Heroin Use')\n",
    "plt.ylabel('Feeling Bad About Yourself Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Violin Plot\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "sns.violinplot(data=clean_df, x='Heroin_Use', y=Y)\n",
    "plt.title('Violin Plot by Heroin Use')\n",
    "plt.ylabel('Feeling Bad About Yourself Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Histogram with overlay\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "for group_name, group_data in clean_df.groupby('Heroin_Use'):\n",
    "    plt.hist(group_data[Y], alpha=0.6, label=f'{group_name} (n={len(group_data)})', \n",
    "             bins=np.arange(clean_df[Y].min(), clean_df[Y].max()+2)-0.5, \n",
    "             density=True)\n",
    "plt.xlabel('Feeling Bad About Yourself Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Histogram by Heroin Use')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Strip Plot\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "sns.stripplot(data=clean_df, x='Heroin_Use', y=Y, size=4, alpha=0.6)\n",
    "plt.title('Strip Plot by Heroin Use')\n",
    "plt.ylabel('Feeling Bad About Yourself Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Summary statistics bar plot\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "means = clean_df.groupby('Heroin_Use')[Y].mean()\n",
    "stds = clean_df.groupby('Heroin_Use')[Y].std()\n",
    "x_pos = range(len(means))\n",
    "plt.bar(x_pos, means, yerr=stds, capsize=5, alpha=0.7)\n",
    "plt.xlabel('Heroin Use')\n",
    "plt.ylabel('Mean Feeling Bad About Yourself Score')\n",
    "plt.title('Mean ± SD by Heroin Use')\n",
    "plt.xticks(x_pos, means.index, rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. DETAILED KERNEL DENSITY PLOT (SEPARATE FIGURE)\n",
    "print(\"\\nCreating detailed kernel density plot...\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create more detailed KDE plot\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "for i, (group_name, group_data) in enumerate(clean_df.groupby('Heroin_Use')):\n",
    "    if len(group_data) > 1:\n",
    "        # Calculate KDE\n",
    "        kde_data = group_data[Y].dropna()\n",
    "        density = stats.gaussian_kde(kde_data)\n",
    "        xs = np.linspace(clean_df[Y].min(), clean_df[Y].max(), 200)\n",
    "        density_values = density(xs)\n",
    "        \n",
    "        # Plot\n",
    "        plt.fill_between(xs, density_values, alpha=0.4, color=colors[i % len(colors)], \n",
    "                        label=f'{group_name} (n={len(kde_data)})')\n",
    "        plt.plot(xs, density_values, color=colors[i % len(colors)], linewidth=2)\n",
    "\n",
    "plt.xlabel('Feeling Bad About Yourself Score', fontsize=12)\n",
    "plt.ylabel('Probability Density', fontsize=12)\n",
    "plt.title('Kernel Density Estimation: Feeling Bad About Yourself by Heroin Use', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. SUMMARY TABLE FOR EXPORT\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"6. SUMMARY TABLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create comprehensive summary table\n",
    "summary_stats = []\n",
    "for group_name, group_data in clean_df.groupby('Heroin_Use'):\n",
    "    y_data = group_data[Y]\n",
    "    stats_dict = {\n",
    "        'Group': group_name,\n",
    "        'N': len(y_data),\n",
    "        'Mean': y_data.mean(),\n",
    "        'Std': y_data.std(),\n",
    "        'Min': y_data.min(),\n",
    "        'Q1': y_data.quantile(0.25),\n",
    "        'Median': y_data.median(),\n",
    "        'Q3': y_data.quantile(0.75),\n",
    "        'Max': y_data.max(),\n",
    "        'Skewness': stats.skew(y_data),\n",
    "        'Kurtosis': stats.kurtosis(y_data)\n",
    "    }\n",
    "    summary_stats.append(stats_dict)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "print(\"\\nComprehensive Summary Statistics:\")\n",
    "print(summary_df.round(3))\n",
    "\n",
    "# Save summary table\n",
    "summary_df.to_csv('nhanes_summary_stats.csv', index=False)\n",
    "print(f\"\\nSummary statistics saved to 'nhanes_summary_stats.csv'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
